# -*- coding: utf-8 -*-
"""Autoencoder per MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ewV8rOu_1dEKn6EYoYFSwQn4kseE-5Sj

# Autoencoder per MNIST

## Introduzione

Un **autoencoder** è una rete neurale usata per l’*apprendimento non supervisionato* in grado di creare una rappresentazione dei dati in ingresso in modo efficiente.

In un autoencoder i dati in uscita sono identici a quelli in ingresso. L’obiettivo di un autoencoder è quello di rappresentare la struttura del dato. Essi osservano i dati di input, elaborano una rappresentazione efficiente degli stessi producendo degli ouput simili ai dati d’ingresso. La rete comprime i dati in ingresso in uno spazio *latente* e li ricostruisce a partire da questo stesso spazio.

### Struttura di un autoencoder

Un autoencoder è costituito da:
1. una *rete di riconoscimento* chiamata **encoder** che converte gli input nelle rappresentazioni interne;
2. un *rete generativa* chiamata **decoder** che converte la rappresentazione interna in un output.

Lo strato intermedio tra encoder e decoder si chiama **code**.
L'autoencoder ha una struttura simmetrica: a partire dall'encoder fino al code, il numero di nodi diminuisce; viceversa, a partire dal code fino al decoder, il numero di nodi aumenta. Proprio perchè l'autoencoder è simmetrico (e perchè un autoencoder deve restituire in output lo stesso dato ricevuto in input), lo strato finale del decoder deve avere lo stesso numero di neuroni dello strato di input del encoder.

### Applicazioni

Di seguito si elencano solo alcune applicazioni degli autoencoder:
1. **Image processing** (image denoising, image compression);
2. **Anomaly detection**;
3. **Riduzione della dimensionalità**: l'obiettivo è trovare un metodo di proiezione appropriato, che mappa i dati dallo spazio con caratteristiche elevate a quello con caratteristiche ridotte. Il concetto principale è simile a quello del **Principal Components Analysis (PCA)**. La differenza è che la PCA utilizza una funzione di attivazione lineare, mentre gli autoencoder utilizzano delle funzioni di attivazione non lineari. Se si realizza un autoencoder con una funzione di attivazione lineare, la soluzione ottima trovata è fortemente correlata alla PCA.

## Autoencoding

### Analisi del dataset

Includo il dataset e tutte le librerie necessarie.
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from tensorflow.keras import losses
from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose, MaxPool2D, Flatten, Activation, Dropout, MaxPooling2D, Reshape, Input
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model

"""Preparo i dati di train e di test."""

(X_train, _), (X_test, y_test) = mnist.load_data()

"""Ottengo alcune informazioni riguardo il dataset. É possibile vedere che il dataset è costituito da 7000 immagini."""

print (X_train.shape)
print (X_test.shape)

"""### Preprocessing

I pixel delle immagini hanno valori che cadono nell'intervallo da 0 a 255. Questi valori vanno scalati in un intervallo tra 0 e 1 prima di poterli utilizzare per la realizzazione della rete. Per fare ciò, si dividono i valori per 255. È importante che l'insieme di train e l'insieme di test vengano preprocessati in ugual modo.
"""

X_train = X_train / 255.0
X_test = X_test / 255.0

"""### Costruzione della rete

Definisco una classe in cui realizzo un **encoder** e un **decoder**. Per entrambi definisco quali sono gli strati utilizzati e i relativi parametri.
"""

class Autoencoder(Model):
  def __init__(self):
    super(Autoencoder, self).__init__()

    self.encoder = tf.keras.Sequential([
      Flatten(),
      Dense(64, activation='relu'),
    ])
    self.decoder = tf.keras.Sequential([
      Dense(784, activation='sigmoid'),
      Reshape((28, 28))
    ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Autoencoder()

"""Come funzione di *loss* posso utilizzare la funzione *mean squared error* perchè i valori in ingresso sono nell'intervallo [0, 1]."""

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

"""Mostro qual è l'architettura dell'*encoder*."""

plot_model(autoencoder.encoder, show_layer_names=False, show_shapes=True)

"""Mostro qual è l'architettura del *decoder*."""

plot_model(autoencoder.decoder, show_layer_names=False, show_shapes=True)

"""Eseguo l'addestramento della rete."""

history = autoencoder.fit(X_train, X_train,
                epochs=10,
                shuffle=True,
                validation_data=(X_test, X_test))

"""Salvo le immagini codificate dall'encoder e quelle decodificate dal decoder."""

encoded_images = autoencoder.encoder(X_test).numpy()
decoded_images = autoencoder.decoder(encoded_images).numpy()

"""Mostro le prime 10 immagini prese dall'insieme di test. Per ognuna di esse, mostro sia l'immagine originale, sia quella processata dall'autoencoder."""

n = 10
plt.figure(figsize=(20, 4))

for i in range(n):
  # show original handwritten digits
  ax = plt.subplot(2, n, i + 1)
  plt.imshow(X_test[i])
  plt.title("original")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

  # show handwritten digits after autoencoder computation
  ax = plt.subplot(2, n, i + 1 + n)
  plt.imshow(decoded_images[i])
  plt.title("reconstructed")
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)

plt.show()

"""## Riduzione del rumore nelle immagini

### Split del dataset

Preparo i dati di train e di test.
"""

(X_train, _), (X_test, y_test) = mnist.load_data()

"""### Preprocessing

Eseguo le medesime operazioni fatte precedentemente.
"""

X_train = X_train / 255.0
X_test = X_test / 255.0

X_train = X_train[..., tf.newaxis]
X_test = X_test[..., tf.newaxis]

"""Aggiungo del rumore casuale alle immagini."""

noise_factor = 0.2
X_train_noisy = X_train + noise_factor * tf.random.normal(shape=X_train.shape) 
X_test_noisy = X_test + noise_factor * tf.random.normal(shape=X_test.shape) 

X_train_noisy = tf.clip_by_value(X_train_noisy, clip_value_min=0., clip_value_max=1.)
X_test_noisy = tf.clip_by_value(X_test_noisy, clip_value_min=0., clip_value_max=1.)

"""Mostro le immagini originali con l'aggiunta del rumore."""

n = 10
plt.figure(figsize=(20, 2))

for i in range(n):
    ax = plt.subplot(1, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(X_test_noisy[i]))
    plt.gray()

plt.show()

"""### Costruzione della rete

Definisco una nuova classe in cui realizzo un encoder e un decoder. Per entrambi definisco quali sono gli strati utilizzati e i relativi parametri.
"""

class Denoise(Model):
  def __init__(self):
    super(Denoise, self).__init__()
    self.encoder = tf.keras.Sequential([
      Conv2D(64, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)),
      Conv2D(32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform')
      ])

    self.decoder = tf.keras.Sequential([
      Conv2DTranspose(32, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform'),
      Conv2DTranspose(64, kernel_size=(3,3), activation='relu', kernel_initializer='he_uniform'),
      Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')
      ])

  def call(self, x):
    encoded = self.encoder(x)
    decoded = self.decoder(encoded)
    return decoded

autoencoder = Denoise()

autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())

"""Eseguo l'addestramento della rete."""

history = autoencoder.fit(X_train_noisy, X_train,
                epochs=10,
                shuffle=True,
                validation_data=(X_test_noisy, X_test))

"""Salvo le immagini codificate dall'encoder e quelle decodificate dal decoder."""

encoded_images = autoencoder.encoder(X_test).numpy()
decoded_images = autoencoder.decoder(encoded_images).numpy()

"""Mostro le prime 10 immagini prese dall'insieme di test. Per ognuna di esse, mostro sia l'immagine originale con l'aggiunta del rumore, sia quella processata dall'autoencoder."""

n = 10
plt.figure(figsize=(20, 4))
for i in range(n):

    # show original handwritten digits with noise
    ax = plt.subplot(2, n, i + 1)
    plt.title("original + noise")
    plt.imshow(tf.squeeze(X_test_noisy[i]))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # show handwritten digits after autoencoder computation
    bx = plt.subplot(2, n, i + n + 1)
    plt.title("reconstructed")
    plt.imshow(tf.squeeze(decoded_images[i]))
    plt.gray()
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
plt.show()

"""L'autoencoder ha eliminato correttamente il rumore in eccesso e ha ricostruito quelle parti della cifra alterate dal rumore."""