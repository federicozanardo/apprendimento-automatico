# -*- coding: utf-8 -*-
"""Naive Bayes per Twenty User Newsgroups.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EP5l6bvfik2rhso8l360fzC-NtZmr7NU

# Naive Bayes per Twenty User Newsgroups

## Caricamento del dataset e delle librerie necessarie
"""

from sklearn.datasets import fetch_20newsgroups

from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.naive_bayes import MultinomialNB, ComplementNB
from sklearn.metrics import classification_report

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

"""Si ottenga la descrizione fornita dal dataset stesso."""

print(fetch_20newsgroups().DESCR)

"""Si illustrino i valori target del dataset."""

fetch_20newsgroups().target_names

"""Si memorizzino in una lista le categorie per cui effettuare la classificazione."""

categories = ['comp.os.ms-windows.misc', 
              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 
              'comp.windows.x']

"""## Prima versione

Si preparino i dati di training e i dati di test.
"""

train = fetch_20newsgroups(subset='train', categories=categories, random_state=42)
test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)

"""Si osservi il primo elemento contenuto nell'insieme di training."""

train.data[0]

train.target[0]

"""### Preprocessing e model selection

`TfidfVectorizer` esegue il preprocessing dei dati. In particolare, trasforma il testo in vettori di caratteristiche che possono essere utilizzati come input per lo stimatore. `TfidfVectorizer` corrisponde ad eseguire prima `CountVectorizer` e poi `TfidfTransformer`.

Si utilizzi la Grid Search Cross Validation per determinare i parametri che permettono di ottenere dei modelli performanti sul dataset. Si crei un dizionario di dizionari che contiene la griglia dei parametri per i classificatori Naive Bayes.
"""

p_grid = {
    'clf__alpha': (0.0001, 0.001, 0.01, 0.1, 1),
    'tfidf__norm': ('l1', 'l2'),
    'tfidf__stop_words': (None, 'english'),
    'tfidf__use_idf': (True, False)
}

"""Si definisca la pipeline per il modello `MultinomialNB`."""

multinomial_nb_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(analyzer='word')),
    ('clf', MultinomialNB())
])

"""Si definisca la pipeline per il modello `ComplementNB`."""

complement_nb_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(analyzer='word')),
    ('clf', ComplementNB())
])

"""Si effettui Grid Search Cross Validation per `MultinomialNB`."""

clf = GridSearchCV(multinomial_nb_pipeline, param_grid=p_grid, cv=5, scoring='accuracy')
clf.fit(train.data, train.target)

print("VALIDATION score:", clf.best_score_)
print("BEST parameters:", clf.best_params_)

best_parameters = clf.best_estimator_.get_params()
for param_name in sorted(p_grid.keys()):
    print("\t%s: %r" % (param_name, best_parameters[param_name]))

y_pred = clf.predict(test.data)
y_test = test.target

print(classification_report(y_test, y_pred))

"""Si effettui la Grid Search Cross Validation per `ComplementNB`."""

clf = GridSearchCV(complement_nb_pipeline, param_grid=p_grid, cv=5, scoring='accuracy')
clf.fit(train.data, train.target)

print("VALIDATION score:", clf.best_score_)
print("BEST parameters:", clf.best_params_)

best_parameters = clf.best_estimator_.get_params()
for param_name in sorted(p_grid.keys()):
    print("\t%s: %r" % (param_name, best_parameters[param_name]))

y_pred = clf.predict(test.data)
y_test = test.target

print(classification_report(y_test, y_pred))

"""## Seconda versione

Il dataset originale contiene delle informazioni che suggeriscono già per ogni esempio qual è la classificazione. Infatti è possibile vedere che:
* Quasi ogni gruppo si distingue in base al fatto che nelle intestazioni appaiono delle informazioni che suggeriscono la classificazione dell'esempio;
* Un'altra caratteristica significativa riguarda se il mittente è affiliato ad un'università, come indicato dalle intestazioni o dalla firma;
* La parola *articolo* è una caratteristica significativa, basata sulla frequenza con cui le persone citano dei post precedenti;
* Altre caratteristiche corrispondono ai nomi e agli indirizzi e-mail di particolari persone che stavano postando in quel momento.

Tutti questi indizi permettono di contraddistinguere i vari newsgroup. Il classificatore quindi deve a malapena identificare gli argomenti dal testo. Per questo motivo, il dataset provvede dei metodi per rimuovere determinate informazioni che possono influenzare la classificazione.

Si rieseguano tutti i passi effettuati precedentemente sul dataset. Nel dataset corrente vengono rimossi:
* *headers*
* *footers*
* *quotes*
"""

train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories, random_state=42)
test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories, random_state=42)

"""Si effettui la Grid Search Cross Validation per `MultinomialNB`."""

clf = GridSearchCV(multinomial_nb_pipeline, param_grid=p_grid, cv=5, scoring='accuracy')
clf.fit(train.data, train.target)

print("VALIDATION score:", clf.best_score_)
print("BEST parameters:", clf.best_params_)

best_parameters = clf.best_estimator_.get_params()
for param_name in sorted(p_grid.keys()):
    print("\t%s: %r" % (param_name, best_parameters[param_name]))

y_pred = clf.predict(test.data)
y_test = test.target

print(classification_report(y_test, y_pred))

"""Si effettui la Grid Search Cross Validation per `ComplementNB`."""

clf = GridSearchCV(complement_nb_pipeline, param_grid=p_grid, cv=5, scoring='accuracy')
clf.fit(train.data, train.target)

print("VALIDATION score:", clf.best_score_)
print("BEST parameters:", clf.best_params_)

best_parameters = clf.best_estimator_.get_params()
for param_name in sorted(p_grid.keys()):
    print("\t%s: %r" % (param_name, best_parameters[param_name]))

y_pred = clf.predict(test.data)
y_test = test.target

print(classification_report(y_test, y_pred))

"""È possibile notare una differenza sostanziale tra i classificatori addestrati nella prima versione del dataset e nella seconda versione.

## Confronto con altri classificatori

In questa sezione verranno svolte dei confronti e delle valutazioni tra classificatori diversi. I classificatori che verranno utilizzati sono:
* Alberi decisionali
* K-Nearest Neighbors
* Naive Bayes
* SVM
"""

import numpy as np

from sklearn.datasets import fetch_20newsgroups

from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB, ComplementNB

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV, KFold

"""Si memorizzino in una lista le categorie per cui effettuare la classificazione."""

categories = ['comp.os.ms-windows.misc', 
              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 
              'comp.windows.x']

"""Si effettui il preprocessing del dataset."""

vectorizer = CountVectorizer() 

sample_set = fetch_20newsgroups(categories=categories, random_state=42)
X_temp = vectorizer.fit_transform(sample_set.data)
y = sample_set.target

tfidf_transformer = TfidfTransformer()
X = tfidf_transformer.fit_transform(X_temp)

"""### **Model selection**

Si definiscano i classificatori che verranno utilizzati nella model selection.
"""

cls_names = ["Decision Tree", 
             "K-Nearest Neighbors", 
             "Naive Bayes Multinomial",
             "Naive Bayes Complement",
             "SVM"] 

classifiers = [DecisionTreeClassifier,
               KNeighborsClassifier,
               MultinomialNB, 
               ComplementNB,
               SVC]

"""Si crei un dizionario di dizionari che contiene la griglia dei parametri per i classificatori."""

p_grid = {
    "dt"  : [{'max_depth': [3, 5, 7, 9]}],
    "knn" : [{'n_neighbors': [3, 5, 7, 9], 'weights': ['uniform', 'distance'], 'algorithm': ['auto']}],
    "mnb" : [{'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}],
    "cnb" : [{'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}],
    "svm" : [
              {"C": [0.25, 0.5, 1, 2], "kernel": ["linear", "rbf"], "gamma" : [0.001, 0.01, 0.1, 1]},
			        {"C": [0.25, 0.5, 1, 2], "kernel": ["poly"], "gamma" : [0.001, 0.01, 0.1, 1], "degree": [2, 3, 4]}
            ],
}
p_grid

"""Si definisca K-Fold Cross Validation con K = 5."""

skf = KFold(n_splits=5, shuffle=False, random_state=42)

best_models, best_scores = [], []

for i, (name, clf, grid) in enumerate(zip(cls_names, classifiers, p_grid)):
  print("\nALGORITHM: ", name)

  fold, models, scores = 1, [], []

  for train, test in skf.split(X, y):
    print("\nFOLD:", fold)
    
    X_train = X[train]
    X_test = X[test]

    gridCV = GridSearchCV(clf(), param_grid=p_grid[grid], cv=5, scoring='accuracy', n_jobs=-1)
    gridCV.fit(X_train, y[train].ravel())

    print("VALIDATION score:", gridCV.best_score_)
    print("BEST parameters:", gridCV.best_params_)

    y_pred = gridCV.predict(X_test)
    y_test = y[test]

    print(classification_report(y_test, y_pred))
    print(confusion_matrix(y_test, y_pred))

    acc = accuracy_score(y_test, y_pred)
    print("TEST score:", str(acc))
    print()

    models.append({"name": name,
                   "validation_score":  gridCV.best_score_,
                   "params":            gridCV.best_params_,
                   "test_score":        str(acc),
                   "report":            classification_report(y_test, y_pred),
                   "confusion_matrix":  confusion_matrix(y_test, y_pred)})
    
    scores.append(gridCV.best_score_)

    fold += 1

  best_model = models[np.argmax(scores)]
  best_score = scores[np.argmax(scores)]

  print("\nBEST MODEL\n")
  print("Validation score: ", best_model["validation_score"])
  print("Params: ",           best_model["params"])
  print("Test score: ",       best_model["test_score"])
  print("Report\n",           best_model["report"])
  print("Confusion matrix\n", best_model["confusion_matrix"])

  best_models.append(best_model)
  best_scores.append(best_score)

"""Si illustri il modello che ha performato meglio nella fase di model selection."""

best_model = best_models[np.argmax(best_scores)]

print("Name: ",             best_model["name"])
print("Validation score: ", best_model["validation_score"])
print("Params: ",           best_model["params"])
print("Test score: ",       best_model["test_score"])
print("Report\n",           best_model["report"])
print("Confusion matrix\n", best_model["confusion_matrix"])

"""### **Test dei classificatori**

Si rieseguano i passi precedenti (preprocessing e split del dataset).
"""

categories = ['comp.os.ms-windows.misc', 
              'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 
              'comp.windows.x']

train = fetch_20newsgroups(subset='train', categories=categories, random_state=42)
test = fetch_20newsgroups(subset='test', categories=categories, random_state=42)

vectorizer = CountVectorizer() 

X_train_temp = vectorizer.fit_transform(train.data)
X_train = tfidf_transformer.fit_transform(X_train_temp)
y_train = train.target

X_test_temp = vectorizer.transform(test.data)
X_test = tfidf_transformer.transform(X_test_temp)
y_test = test.target

"""Si illustrino le accuratezze dei modelli, determinati nella fase di model selction, applicati al dataset complessivo."""

dt = DecisionTreeClassifier(max_depth=9)
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

knn = KNeighborsClassifier(algorithm='auto', n_neighbors=9, weights='distance', n_jobs=-1)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

mnb = MultinomialNB(alpha=0.1)
mnb.fit(X_train, y_train)
y_pred = mnb.predict(X_test)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

cnb = ComplementNB(alpha=1)
cnb.fit(X_train, y_train)
y_pred = cnb.predict(X_test)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

svm = SVC(C=2, gamma=1, kernel='rbf')
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

print(accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))